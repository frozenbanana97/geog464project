{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project to Obtain and download/manipulate the results of Sentinel 1 data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating an RBG of the study area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requirements\n",
    "import asf_search as asf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtaining and printing the results of Sentinel 1 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = asf.search(platform=asf.PLATFORM.SENTINEL1, maxResults=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "opts = {\n",
    "    'platform': asf.PLATFORM.SENTINEL1,\n",
    "    'maxResults': 5\n",
    "}\n",
    "#setting up search parameter options in a dictionary\n",
    "results = asf.search(**opts)\n",
    "#print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geographic Searches!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using a Well Knon Text (WKT) variable to define a polygon for the search to use\n",
    "#It is here I will attempt to use a shapefile or similar that someone can input to define the area, maybe even a search fora city name?\n",
    "geo_results = asf.geo_search(\n",
    "        intersectsWith='POLYGON((-152.81 58.49,-154.90 57.49,-155.08 56.30,-153.82 56.34,-151.99 57.30,-151.43 58.19,-152.81 58.49))',\n",
    "        platform=asf.PLATFORM.ALOS,\n",
    "        start='2010-01-01',\n",
    "        end='2010-02-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137 results found\n"
     ]
    }
   ],
   "source": [
    "print(f'{len(geo_results)} results found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 results found\n"
     ]
    }
   ],
   "source": [
    "#reduce the amount of results by using a centroid of a shape/scene\n",
    "centroid = results[0].centroid().wkt\n",
    "\n",
    "centroid_results = asf.geo_search(intersectsWith=centroid, **opts)\n",
    "\n",
    "print(f'{len(centroid_results)} results found')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing a Product Search<br>\n",
    "See [Vertex](https://search.asf.alaska.edu/#/?zoom=7.370&center=-134.548,55.753&resultsLoaded=true&searchType=List%20Search&searchList=S1A_IW_GRDH_1SDV_20190809T001336_20190809T001401_028485_033839_78A1-GRD_HD,S1A_IW_GRDH_1SDV_20150322T000454_20150322T000524_005137_006794_56E3-GRD_HD,S1A_IW_GRDH_1SDV_20160121T001256_20160121T001321_009585_00DF26_5B84-GRD_HD,S1A_IW_GRDH_1SDV_20151117T000448_20151117T000513_008637_00C455_3DC2-GRD_HD&listSearchType=Product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_list = [\n",
    "    'S1A_IW_GRDH_1SDV_20190809T001336_20190809T001401_028485_033839_78A1-GRD_HD',\n",
    "    'S1A_IW_GRDH_1SDV_20150322T000454_20150322T000524_005137_006794_56E3-GRD_HD',\n",
    "    'S1A_IW_GRDH_1SDV_20160121T001256_20160121T001321_009585_00DF26_5B84-GRD_HD',\n",
    "    'S1A_IW_GRDH_1SDV_20151117T000448_20151117T000513_008637_00C455_3DC2-GRD_HD'\n",
    "]\n",
    "#Prodcuts were found using ASF's Vertex online app "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 results found\n"
     ]
    }
   ],
   "source": [
    "results = asf.product_search(product_list)\n",
    "\n",
    "print(f'{len(results)} results found')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline Searches - Creating image stacks<br>\n",
    "Not needed for me\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading Data\n",
    "#### Before You Start\n",
    "The steps outlined in this demonstration assume `asf_search` is available in your environment. For guidance on installing `asf_search`, [begin here](./1-Basic_Overview.ipynb#Before-You-Start).\n",
    "\n",
    "Additionally, this section expects you to have an [Earthdata Login](https://urs.earthdata.nasa.gov/) account with the appropriate applications authorized, EULAs signed, and profile fields set. The easiest way to check that your EDL account is in order is to simply go to [Vertex](https://search.asf.alaska.edu) and download a product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "dirs = ['downloads']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "import asf_search as asf\n",
    "import getpass\n",
    "\n",
    "username = input('Username:')\n",
    "password = getpass.getpass('Password:')\n",
    "\n",
    "try:\n",
    "    user_pass_session = asf.ASFSession().auth_with_creds(username, password)\n",
    "except asf.ASFAuthenticationError as e:\n",
    "    print(f'Auth failed: {e}')\n",
    "else:\n",
    "    print('Success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`auth_with_token()`<br>\n",
    "This authentication method accepts an EDL Token which is then included as part of an `Authorization: Bearer` header on any downloads using this session. To generate an EDL Token, [sign in to EDL](https://urs.earthdata.nasa.gov/home), select the \"Generate Token\" tab, and then click the green \"Generate Token\" button. The token can then be copied and used below.\n",
    "  \n",
    "__Note:__ While it is extremely convenient, not all datapool hosts are compatible with this authentication method yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "token = getpass.getpass('EDL Token:')\n",
    "\n",
    "token_session = asf.ASFSession().auth_with_token(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " `auth_with_cookiejar()`<br>\n",
    "This method accepts an `http.cookiejar` compatible object, such as a previously authenticated session stored for later re-use.\n",
    "\n",
    "For this demonstration, we will make use of the cookiejar from one of the previously authenticated sessions above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cookiejar = user_pass_session.cookies #take username and password session cookies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cookiejar_session = asf.ASFSession().auth_with_cookiejar(cookiejar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Downloading\n",
    "[View this search in Vertex](https://search.asf.alaska.edu/#/?dataset=UAVSAR&productTypes=METADATA&resultsLoaded=true&zoom=8.090&center=-90.488,28.359&polygon=POLYGON((-91.97%2028.78,-88.85%2028.78,-88.85%2030.31,-91.97%2030.31,-91.97%2028.78)))\n",
    "  \n",
    "With authentication handled, we can now begin downloading products. First, we will need some search results to work with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "from os import mkdir\n",
    "\n",
    "downPath = './downloads'\n",
    "isDir = os.path.isdir(downPath)\n",
    "\n",
    "if isDir == False:\n",
    "    mkdir('downloads')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250 results found\n"
     ]
    }
   ],
   "source": [
    "#get metadata search results as a quick example\n",
    "results = asf.geo_search(\n",
    "    intersectsWith='POLYGON((-91.97 28.78,-88.85 28.78,-88.85 30.31,-91.97 30.31,-91.97 28.78))',\n",
    "    platform=asf.PLATFORM.UAVSAR,\n",
    "    processingLevel=asf.PRODUCT_TYPE.METADATA,\n",
    "    maxResults=250)\n",
    "\n",
    "print(f'{len(results)} results found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['atchaf_19809_21056_009_210913_L090_CX_01.ann']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from os import listdir\n",
    "\n",
    "results[0].download(path='./downloads', session=user_pass_session)\n",
    "\n",
    "listdir('./downloads')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kyle\\OneDrive\\School\\Concordia\\8_W22\\GEOG_464_GIS_Programming\\464TermProject\\.venv_464Project\\lib\\site-packages\\asf_search\\download\\download.py:61: UserWarning: File already exists, skipping download: ./downloads\\atchaf_19809_21056_009_210913_L090_CX_01.ann\n",
      "  warnings.warn(f'File already exists, skipping download: {os.path.join(path, filename)}')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['atchaf_06309_21056_004_210913_L090_CX_01.ann',\n",
       " 'atchaf_06309_21056_006_210913_L090_CX_01.ann',\n",
       " 'atchaf_06309_21056_008_210913_L090_CX_01.ann',\n",
       " 'atchaf_19809_21056_003_210913_L090_CX_01.ann',\n",
       " 'atchaf_19809_21056_005_210913_L090_CX_01.ann',\n",
       " 'atchaf_19809_21056_007_210913_L090_CX_01.ann',\n",
       " 'atchaf_19809_21056_009_210913_L090_CX_01.ann',\n",
       " 'pfourc_13320_21055_023_210912_L090_CX_01.ann',\n",
       " 'wterre_16300_21055_021_210912_L090_CX_01.ann',\n",
       " 'wterre_34202_21055_022_210912_L090_CX_01.ann']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0:10].download(path='./downloads', session=user_pass_session)\n",
    "listdir('./downloads')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "87e9bcdd25f1ddc29228cea29646c5d27f6e00675a318c67751279e99a7b1f9d"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
